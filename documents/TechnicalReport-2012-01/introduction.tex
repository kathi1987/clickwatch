\section{Introduction}

\subsection{Problem Statement}
Large models (directed labelled graphs with a inherent spanning tree) cannot be maintained in computer memory. Large models need to be fragmented into smaller models. These smaller parts can be loaded and worked with. This is practical, since most applications only require to handle a small part of a large model at a time. 

We distinguish between large and \emph{extra large} models. Large models are to big for computer memory, but still small enough to be served from a single computer: large models are small enough for common hard drives and a single computer can bear the load from accessing the model (small number of users, infrequent access, only small chunks are accessed). Extra large models require a distributed data store, because they are either to big or are used in a way that a single computer can not handle the load. Safety, redundancy, dependability, etc. are other qualities that we associate with extra large models and their storage. 

Modern key value data stores, can (in principle) store extra large models. They provide all necessary qualities associated with extra large models (distributed, safe, redundant, dependable, scalability, etc.). The problem is that models have to be fragmented so that they can be accessed in part. The concrete fragmentation of a model and its granularity directly influences the performance of storing, accessing, and working with the model. Here, performance regards execution time, CPU load, and RAM memory usage. 

\subsection{Fragmentation}

Models (or data, or information) in this paper are directed labelled graphs (with an inherent spanning tree). Common model representations are EMF-based models or XML documents. We assume that nodes and all their outgoing edges always belong together and are inseparable\footnote{This is in direct contrast to ER/SQL based models and stores, where links between entities are stored in separate tables}. Often we will only write about nodes, but also mean all their outgoing edges (references to other nodes). For that matter a model is just a set of nodes (objects).

A \emph{fragmentation} of a model is a set of sets of objects. The union of all sets in a fragmentation is the model; all sets are disjunct. The sets in a fragmentation are called \emph{fragments}. The objects in each fragment contain a single spanning tree (sub tree of the models spanning tree). Each fragment is identified by a unique key. The fragment key identifies the root of that tree. Model edges can be associated with keys to reference objects in a different fragment.  

\subsection{Existing Storage Solutions and Fragmentation Strategies}

There are three existing fragmentation strategies:
\begin{itemize}

\item \emph{No fragmentation}, the model is not fragmented. Large models are not possible.
\item \emph{Total fragmentation}, each object of the model (a node with all its outgoing edges) is stored in its own fragment.
\item \emph{Manual fragmentation}, the user determines which objects of a model comprise which fragments.
\end{itemize} 

\subsection{Key Value Stores}

Key value stores technical systems that persist large (hash-)maps. They can store arbitrary values (string or byte arrays) under arbitrary keys (string or byte arrays). There are different mature solutions for different environments (grid, cluster, cloud). A key-value combination is called \emph{entry}.

Key value stores can be \emph{distributed} or \emph{non distributed}; they can be \emph{ordered} or {unordered}. Generally values access complexity is logarithmic to the size the stored map (number of keys). This is true for both non distributed and distributed stores. In distributed stores complexity also depends logarithmically on the size of the store (number of computers (nodes) in the store). Reading an access value is linear to the size of the value. In distributed stores is a possibility to read values in parallel. In ordered stores, subsequent keys of an already accessed key can be accessed in constant time (scan). In general models are serialized and need parsing to be used. A loaded value (model fragment) is parsed in linear time (depending on the fragments size). We assume that parsing can only be performed on the client and no parallel parsing on different computers is possible. 

\subsection{Detailed Problems}

There are several distinct problems with fragmentation of (extra) large models:
\begin{itemize}
\item Trivial fragmentation (no or total) might not produce optimal or even functional results. 

\item In extreme broad models one object might be too big (too many outgoing edges). Too big to be stored in RAM memory, or too big for reasonable and efficient use. This happens for example with sensor data collected over long periods of time. On sensor (object, node) holds references (edges) to thousands of thousands of values.  

\item There are several parameters that influence optimal fragmentation: parsing speed, data store access speed, whether parsing or accesses different entries can be parallelized (distribute scenario). Random access (random read) vs. sequential access (scan). 

\item Fragmentation in general depends on model usage patterns. These cannot be known at model creation and might change over time.
\end{itemize}

\subsection{Terms}

Specific terms are: \emph{model}, \emph{large model}, \emph{extra large model}, \emph{fragmentation}, \emph{fragment}, \emph{no fragmentation}, \emph{total fragmentation}, \emph{manual fragmentation}, \emph{key-value data store}, \emph{entry}, \emph{key}, \emph{value}, \emph{(un-)ordered store}, \emph{(non-)distributed store}. Further terminology may be introduced later.

