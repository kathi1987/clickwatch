\section{Introduction}

Modeling frameworks (e.g. EMF or kermeta) can only work with models if they are loaded into a computer's RAM. This limits the possible size of a model. 
Modeling frameworks provide only limited capabilities to deal with large models (i.e. lazy loading in EMF). 
Other frameworks (e.g. CDO) persist models in data bases and load and unload single model objects on demand. This allows to work with models of arbitrary size. 
Data base persistence is RAM efficient and practically solves today's model size issues, but we claim that existing approaches are not time efficient. 
Here, time efficiency relates to the execution time for common modeling tasks. In this paper, we look at the following tasks (1) creating and extending models, (2) traversing models (as necessary during model transformation), (3) querying models, and (4) loading parts of models (i.e. loading a diagram into an editor). 

An obvious observation is that many modeling tasks (especially traversing models and loading parts of models) require to load large chunks of the model. Existing data base persistence frameworks, store and access model objects individually. If a tasks requires to load a larger part of the model, all its objects are still accessed individually from the underlying data base.

Our hypothesis is that modeling tasks can be executed faster, if models are represented as larger aggregates within an underlying data base. Storing models as aggregates of objects and not as single objects reduces the number of data base accesses, or as Martin Fowler puts it on his blog: \emph{"Storing aggregates as fundamental units makes a lot of sense} [...]\emph{, since you have a large clump of data that you expect to be accessed together"},~\cite{martinFowler}. This already raises the three main questions that we want to answer with this paper: Are there aggregates that are \emph{often} accessed together? How can we create them automatically and transparently? What actual influence on the performance has the choice of concrete aggregates?

To answer these question, we will proceed as follows: First (section~\ref{sec:applications}), we look at typical modeling applications: which model sizes they work with and what concrete modeling tasks are used predominantly. This will give us an idea of what aggregates could be and how often aggregates can be expected to be actually accessed together. 
Secondly (section~\ref{sec:fragmentation}), we will present our aggregation approach. This approach is based on fragmenting models along their inherent spanning tree (composite tree). We will reason, that most modeling tasks need to load sub-trees of this composite tree, and that such sub-trees (model fragments) make reasonable aggregates. 
In the related work section~\ref{sec:related_work}, we present existing model persistence frameworks and interpret their strategies with respect to the idea of fragmentation.
In the next section, we provide a theoretical analysis of performance under optimal fragmentation to provide some bounds for efficiency expectations.
In section~\ref{sec:implemention}, we finally present a framework that implement our fragmentation concept.
The next section is the evaluation section, where we compare our framework to existing frameworks with respect to time and memory efficient execution of common modeling tasks. Furthermore, we use our framework to analyse the influence of the amount of fragmentation on performance.
We close the paper with conclusions and further work. 

