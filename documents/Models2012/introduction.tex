\section{Introduction}

Modeling frameworks (e.g. the Eclipse Modelling Framework (EMF) or kermeta) can only work with a model when it is fully loaded into a computer's main memory (RAM), even though not all model objects are used at the same time.
This limits the possible size of a model. 
Modeling frameworks themselves provide only limited capabilities to deal with large models (i.e. resources and resource lazy loading in EMF). 
Model persistence frameworks (e.g. Connected Data Objects (CDO)) on the other hand, store models in data bases and load and unload single model objects on demand. 
Only those objects that are used at the same time need to be maintained in main memory at the same time. This allows to work with models larger than the main memory otherwise allows. 

We claim that existing data base persistence solutions may provide a main memory efficient solution to the model size issue, but not a time efficient one. In this paper, time efficiency always relates the time it takes for a single execution of one of four abstract modeling tasks. These tasks are (1) creating and extending models, (2) traversing models (e.g. as necessary during model transformation), (3) querying models, and (4) loading parts of models (i.e. loading a diagram into an editor).

An obvious observation is that some of these modeling tasks (especially traversing models and loading parts of models) require to load large numbers of model objects eventually. Existing persistence frameworks, store and access model objects individually. If a tasks requires to load a larger part of the model, all its objects are still accessed individually from the underlying data base. This is time consuming.

Our hypothesis is that modeling tasks can be executed faster, if models are mapped to larger aggregates within an underlying data base. Storing models as aggregates of objects and not as single objects reduces the number of required data base accesses, or as Martin Fowler puts it on his blog: \emph{"Storing aggregates as fundamental units makes a lot of sense} [...]\emph{, since you have a large clump of data that you expect to be accessed together"},~\cite{martinFowler}. This hypothesis raises three major questions: Do models contain aggregates that are \emph{often} accessed together? How can we determine aggregates automatically and transparently? What actual influence on the performance has the choice of concrete aggregates?

To answer these question, we will proceed as follows: First (section~\ref{sec:applications}), we look at three typical modeling applications: which model sizes they work with and what concrete modeling tasks they perform predominantly. This will give us an idea of what aggregates could be and how often aggregates can be expected to be actually accessed together. 
Secondly (section~\ref{sec:fragmentation}), we will present our approach to finding aggregates within models. This approach is based on fragmenting models along their containment hierarchy (a fix inherent spanning tree that exist in each model). We will reason, that most modeling tasks need to access aggregates that are sub-trees of the containment hierarchy (fragments). 
In the related work section~\ref{sec:related_work}, we present existing model persistence frameworks and interpret their strategies with respect to the idea of fragmentation. Furthermore, we discuss key-value stores for persisting fragmented models.
The following section provides a theoretical analysis and upper bound estimation for possible performance gains of optimal fragmentation.
In section~\ref{sec:implemention}, we finally present a framework that implements our fragmentation concept.
The next section is the evaluation section: we compare our framework to existing persistence frameworks with respect to time and memory efficient execution of the four abstract modeling tasks. Furthermore, we use our framework to measure the influence of fragmentation on performance to verify the analytical considerations from section~\ref{sec:fragmentation}.
We close the paper with conclusions and further work. 

