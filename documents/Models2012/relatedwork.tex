\section{Related Work}
\label{sec:related_work}

\subsection{Model Persistence}
For EMF based models, there are at least four different approaches to large models: (1) regular EMF with XMI based persistence; (2) EMF resources, where a resource can be a file or an entry in a data base; (3) CDO~\cite{cdo} and other object relational mappings (ORM) for Ecore; (4) morsa~\cite{morsa2011} a EMF data-base mapping for non-relational data bases.
\footnote{Mentioned memory and time efficiency in this section are taken from the evaluation section~\ref{sec:evaluation}.}

First, regular EMF: Models are persisted as XMI documents and can only be used if loaded completely into a computer's RAM. EMF realises the \emph{no fragmentation} strategy. The memory usage of EMF is linear to the model's size. It's time efficiency is good for small models, since it needs no further managing overhead, but is bad for large models due to pointless garbage collection and extensive allocation of memory.

Secondly, EMF resources~\cite{emf2009}: EMF allows to fragment a model into different resources. Originally, each resource could only contain a separate containment hierarchy and only cross-references were allowed. But since EMF version 2.2 containment proxies are supported. EMF support lazy loading: resources do not have to be loaded manually, EMF loads them transparently once the first object of a resource is accessed. Model objects have to be assigned to resources manually (\emph{manual fragmentation}). To actually save memory the user has to unload resources manually too. Memory efficiency is good if resources are handled properly. Time efficiency is also good due to minimal management overhead. The framework MongoEMF~\cite{mongoEMF} maps resources to entries in a MongoDB~\cite{mongodb2010} data base.

Thirdly, CDO~\cite{cdo}: CDO is a ORM for EMF.~\footnote{Lately, CDO also support non-relational data bases, such as MongoDB~\cite{mongodb2010}. Such features were not evaluated in this paper; but one can assume characteristics similar to those of morsa.}
It supports several relational data bases. Classes and features are mapped to tables and their columns. Objects, references, and attributes are mapped to rows. CDO was designed for software modeling and versioning and provides transaction, views, and versions. These features produce some overhead. 
Relational data bases and SQL provide mechanisms to index and access objects and their features. This allows fast queries, if the user understands the underlying ORM. But, complex table structures and indexes cause very low entry (i.e. object) creation rates. Sorting entries into indexes and tables consumes time.
CDO is RAM efficient. Traversing or loading parts of models is slow, because each object needs to be accessed individually. 

Fourthly, morsa~\cite{morsa2011}: Different to CDO, morsa uses so mongoDB~\cite{mongodb2010}, a no-sql data base. In no-sql data bases (or other key-value stores) store arbitrary values in an key-value map. This simple data structure allows fast and easy distributable data bases. Morsa stores objects, their references and attributes as JSON documents. Morsa furthermore uses mongoDB's index feature to index specific characteristics (e.g. an objects meta-class reference). This produces similar characteristics than with CDO: fast queries, slow creation, traverse, and load.

\subsection{Key-Value Stores}

The general term \emph{data base} has long been used as a synonym for relational data bases. But in the last decade a new kind of data base has become more and more popular. Web and cloud computing require scalability above all, and traditional ACID~\cite{ACID} properties can be sacrificed if the data store is easily distributable. This explains the popularity of so called \emph{No-SQL} data bases or \emph{key-value store}. Such key-value stores only provide a simple map data structure: there are only keys and values. For more information and an comparison of existing key-value stores refer to~\cite{nosql2010}.

Key-value stores are ideal data bases for persisting fragmented models. Fragments can be identified by URIs, which are easily mapped to key-value store keys, and XMI (as native model persistence format) can be used for values. Key-value stores provide a scalable persistent solution with good performance characteristics. This allows to react to increasing requirements for model sizes and number of parallel access (e.g. for the geo-spatial models modelling application).

There are three different applications that inspired three groups of key-value stores. First, there are web applications and the popular MongoDB~\cite{mongodb2010} and CouchDB~\cite{couchdb2010} data bases. These use JSON documents as values and provide additional indexing for JSON attributes.

Secondly, there is cloud computing and commercial Google Big-Table~\cite{bibtable2006} and Amazon's Dynamo~\cite{dynamo2007} inspired data stores. HBase~\cite{hbase2008} and Cassandra~\cite{cassandra2009} are respective open source implementations. Those data bases strive for massive distribution, they provide no support for additional value structuring, but integrate well into map-reduce~\cite{mapreduce} execution frameworks, such as Hadoop (HBase is Hadoop's native data store). 

A third application is high performance computing. Scalaris~\cite{ScalarisTransactions2008} is a key-value store opt for massive parallel, cluster, and grid computing. Scalaris provides mechanisms for consistency and transactions and brings some ACID to key-value stores.

For the implementations in this paper, we use HBase, which provides everything we need and nothing more.