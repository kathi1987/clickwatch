\section{Future Work} 
\label{future_work}

\subsubsection{Sorted and Distributed Key-Value Stores} 

Our fragmentation strategy is based on unsorted key-value store accesses with $\mathcal{O}log$ complexity. Neither our analysis, nor out  implementation EMFFrag, or our evaluation consider sorted key-value stores that allow to access sequential keys with constant time (scans). Neither did we consider distributed key-value stores which would allow parallel access. Key-value stores are easily distributed in peer two peer networks. This is done for two scalability reasons: replication (allows more users to access the same data in less time) and sharding (distributing data to allow faster and larger storage). Fragmentation can have an influence on both.

\subsubsection{Transactions}

If multiple user access/modify transactions become a necessity. Transaction can either be provided by the underlying data store (e.g. with Scalaris~\cite{ScalarisTransactions2008}) or can be implemented into EMFFrag. On non-distributed data stores, a common transaction pattern could be used. More interesting is explore the influence of fragmentation on transactions (and versioning), because the maximum granularity is determined by fragment size.

\subsubsection{Cross-References} 

EMFFrag persists containment references with URIs with a fragment ID pointing to the fragment that contains the reference objects. This does not work for cross references: when an object is moved, its URI changes and all referencing object use invalid URIs. For this reason EMFFrag needs to use a secondary index that maps object IDs to containing fragments. EMFFrag uses URIs with object IDs to persist cross references. To resolve such an URI, the secondary index is used to find the fragment that contains the object. Object IDs and secondary index are only maintained for objects that are actually cross references to keep the index small. 

In our analysis and evaluation, we did not examine the influence of cross references and corresponding indexes on performance. We have to expect that create/modify tasks are performed considerably slower, since two indexes have to be maintained. The impact on traverse, query, or partial loads, on the other hand, should be minimal.

\subsubsection{Large Value Sets}

In large models, single objects can become very large themselves if they hold large sets of attribute values and references. CDO maps an object's feature values to individual entries in a database table and can manage such objects, but does so slowly. EMFFrag (and Morsa), on the other hand, consider objects as atomic entities and large object become a performance burden too. We need to extend the fragmentation idea to large value sets. Similar to all consideration in this paper, these strategies for large value sets have to be optimized and evaluated for the abstract tasks manipulation, iteration (traverse), indexed access (query), and range queries (partial load). 

\section{Conclusions}\label{sec:conclusions}

Large software models consist of upto $10^9$ objects. Models from other application can have a size upto $10^{12}$ objects. Traversing models and loading larger aggregates of objects are common tasks (section~\ref{sec:applications}). Depending on fragment size, partially loading models can be done faster than loading whole models or loading models object by object. There is no optimal fragment size, but intermediate fragment sizes provide a good approximation  (sections~\ref{sec:gains} and~\ref{sec:evaluation}). We provide a persistence framework that allows automatic and transparent fragmentation, if appropriate containment features are marked as fragmentation points in the meta-model (sections~\ref{sec:fragmentation} and~\ref{sec:implemention}). We compared our framework to existing frameworks (EMF XMI, CDO and Morsa) and our framework performs significantly better for creating/manipulating, traversing, and partially loading models. Execution times are 5 to 10 times smaller. Model queries (that favour object-by-object based model persistence with indexes, such as in CDO and Morsa) can be executed with comparable execution times (section~\ref{sec:evaluation}). Model fragmentation also determines the granularity of transactions, which can be a disadvantage. Further problems are single objects with features that can hold large value sets; the fragmentation approach has to be extended for fragmentation of such value sets (section~\ref{sec:future_work}). Our framework stores fragments in key-value stores. Those scale easily (both replication and sharding is supported) and integrate well in peer-to-peer computation scheme (e.g. map-reduce). Fragmentation therefore prepares very large models for modelling in the cloud applications (section~\ref{sec:related_work}).